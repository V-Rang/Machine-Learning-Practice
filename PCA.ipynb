{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5srRZ6XTeLx868fnZWWeT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/V-Rang/Machine-Learning-Practice/blob/main/PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7S8ox7peiw3"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([\n",
        "     [1,2,3,4],\n",
        "     [5,5,6,7],\n",
        "     [1,4,2,3],\n",
        "     [5,3,2,1],\n",
        "     [8,1,2,2]],dtype=float)\n",
        "\n",
        "#procedure:\n",
        "# A : n X m matrix, n observations, m features\n",
        "# Steps:\n",
        "# 1. Standardize A: A[i][j] = (A[i][j]-mu[i])/s[i] where mu[i] and s[i] are mean and standard deviation of ith feature\n",
        "# 2. Form Covariance matrix (m X m) for the feautures: cov[i][j] = sum( (xi-xbar)(yi-ybar)   )/n\n",
        "# 3. Eigendecomposition of covariance matrix\n",
        "# 4. Rearrange eigvec columns in descending order of eigenvalue, resultant matrix: (m X m) \n",
        "# 5. Extract x dominant columns of eigvec matrix\n",
        "# 6. Standardized A (n X m) @ eigvec matrix (m X x) => (n X x) matrix\n",
        "\n",
        "# Compare to pca of StandardScaler scaled A.\n",
        "\n",
        "# **1 StandardScalar calculates std dev as division by N, not N-1. You can use N-1 in manual calculation by setting ddof = 1.\n",
        "# **2 For why we standardize: \n",
        "# https://stats.stackexchange.com/questions/69157/why-do-we-need-to-normalize-data-before-principal-component-analysis-pca\n",
        "\n",
        "# ** 3 When initializing A: do dtype = float, else numpy assumes integers and any manipulation will give integer value, instead of desired floating point values.\n",
        "\n",
        "mu,s = [],[]\n",
        "for i in range(A.shape[1]):\n",
        "  mu.append(np.mean(A[:,i]))\n",
        "  # s.append(np.std(A[:,i],ddof=1))\n",
        "  s.append(np.std(A[:,i]))\n",
        "\n",
        "\n",
        "for i in range(A.shape[1]): #col traversal\n",
        "  for j in range(A.shape[0]): #row traversal\n",
        "    A[j][i] = (A[j][i]-mu[i])/s[i]\n",
        "\n",
        "\n",
        "# print((A[0][1] - mu[0])/s[0])\n",
        "# A[0][1] = (A[0][1] - mu[0])/s[0]\n",
        "\n",
        "# print(A,'\\n')\n",
        "covmat = np.zeros((A.shape[1],A.shape[1]),dtype=float)\n",
        "\n",
        "def covcalc(A,ind1,ind2):\n",
        "  mu1 = np.mean(A[:,ind1])\n",
        "  mu2 = np.mean(A[:,ind2])\n",
        "  val = 0\n",
        "  for i in range(A.shape[0]):\n",
        "    val += (A[i][ind1] - mu1)*(A[i][ind2] - mu2)\n",
        "  val = val/A.shape[0]\n",
        "\n",
        "  return val\n",
        "\n",
        "\n",
        "for i in range(covmat.shape[0]):\n",
        "  for j in range(covmat.shape[1]):\n",
        "    covmat[i][j] = covcalc(A,i,j)\n",
        "\n",
        "# print(covmat)\n",
        "\n",
        "w,v = np.linalg.eig(covmat)\n",
        "\n",
        "#sort in descending order\n",
        "\n",
        "idx = np.argsort(w)\n",
        "# print(idx)\n",
        "idx_rev = np.flip(idx)\n",
        "w_new = w[idx_rev]\n",
        "v_new = v[:,idx_rev]\n",
        "\n",
        "# print(w,'\\n')\n",
        "# print(w_new,'\\n')\n",
        "# print(v,'\\n')\n",
        "# print(v_new,'\\n')\n",
        "\n",
        "pca_self = A@v_new[:,:2]\n",
        "# print(A@v_new[:,:2],'\\n')\n",
        "# print(A)\n",
        "print(pca_self,'\\n')\n",
        "\n",
        "######################################################\n",
        "#Using sklearn.decomposition.PCA\n",
        "\n",
        "A = np.array([\n",
        "     [1,2,3,4],\n",
        "     [5,5,6,7],\n",
        "     [1,4,2,3],\n",
        "     [5,3,2,1],\n",
        "     [8,1,2,2]],dtype=float)\n",
        "import sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "pca2 = PCA(n_components=2)\n",
        "scaling = StandardScaler()\n",
        "scaled_A = scaling.fit_transform(A)\n",
        "# print(scaled_A,'\\n')\n",
        "pca2.fit(scaled_A)\n",
        "pca_A_2 = pca2.transform(scaled_A)\n",
        "print(pca_A_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBPJY8z_gZQk",
        "outputId": "00f426e8-7ed4-4cf0-fe68-052b98b1de14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.56561741e-02  8.45205482e-01]\n",
            " [-2.85829190e+00 -8.72549250e-01]\n",
            " [-5.75566043e-02  1.40104719e+00]\n",
            " [ 1.13385419e+00  2.66995807e-04]\n",
            " [ 1.76633814e+00 -1.37397042e+00]] \n",
            "\n",
            "[[-1.56561741e-02  8.45205482e-01]\n",
            " [ 2.85829190e+00 -8.72549250e-01]\n",
            " [ 5.75566043e-02  1.40104719e+00]\n",
            " [-1.13385419e+00  2.66995807e-04]\n",
            " [-1.76633814e+00 -1.37397042e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "#pca on unscaled data\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(A)\n",
        "pca_A = pca.transform(A)\n",
        "print(pca_A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLsTINkuRwrR",
        "outputId": "0e32dbab-0320-45bd-bb59-643187e3cb7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.40033078e-02  7.55974765e-01]\n",
            " [ 2.55653399e+00 -7.80431775e-01]\n",
            " [ 5.14801919e-02  1.25313470e+00]\n",
            " [-1.01415002e+00  2.38808310e-04]\n",
            " [-1.57986086e+00 -1.22891650e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([\n",
        "     [1,2,3,4],\n",
        "     [5,5,6,7],\n",
        "     [1,4,2,3],\n",
        "     [5,3,2,1],\n",
        "     [8,1,2,2]],dtype=float)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "pca2 = PCA(n_components=2)\n",
        "scaling = StandardScaler()\n",
        "scaled_A = scaling.fit_transform(A)\n",
        "# print(scaled_A,'\\n')\n",
        "pca2.fit(scaled_A)\n",
        "pca_A_2 = pca2.transform(scaled_A)\n",
        "print(pca_A_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K11RsSAMTsGv",
        "outputId": "38fcf39a-dbd8-4d56-c1bd-294aa71f3777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.56561741e-02  8.45205482e-01]\n",
            " [ 2.85829190e+00 -8.72549250e-01]\n",
            " [ 5.75566043e-02  1.40104719e+00]\n",
            " [-1.13385419e+00  2.66995807e-04]\n",
            " [-1.76633814e+00 -1.37397042e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([\n",
        "     [1,2,3,4],\n",
        "     [5,5,6,7],\n",
        "     [1,4,2,3],\n",
        "     [5,3,2,1],\n",
        "     [8,1,2,2]],dtype=float)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "pca3 = PCA(n_components=2)\n",
        "scaling_2 = MinMaxScaler()\n",
        "scaled_A_2 = scaling_2.fit_transform(A)\n",
        "# print(scaled_A)\n",
        "pca3.fit(scaled_A)\n",
        "pca_A_3 = pca3.transform(scaled_A_2)\n",
        "print(pca_A_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwMT61EKWh3s",
        "outputId": "175a68df-a334-421a-feda-ac34453a5fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.57575947 -0.08637201]\n",
            " [ 1.61394275 -0.75358655]\n",
            " [ 0.59188498  0.11654617]\n",
            " [ 0.16947558 -0.42057284]\n",
            " [-0.06253542 -0.9363814 ]]\n"
          ]
        }
      ]
    }
  ]
}